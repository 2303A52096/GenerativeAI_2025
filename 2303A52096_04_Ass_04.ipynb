{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPc8nMhw5TfPblI8MI5fmjP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/2303A52096/GenerativeAI_2025/blob/main/2303A52096_04_Ass_04.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question_01**\n",
        "(1 ponto) Design a simple ANN architecture with one input and one output layer (no hidden\n",
        "layer). Assume a linear activation function in the output layer.\n",
        "\n",
        "• Write Python code for a backpropagation algorithm with gradient descent optimization to update weights and bias parameters of the ANN model with training data shown in Table\n",
        "\n",
        "1.\n",
        "• Calculate the mean square error with training and testing data shown in Table 2.\n",
        "• Write Python code that reads the input data [x1, x2, and x3] from the user. Predict the\n",
        "output with deployed ANN model"
      ],
      "metadata": {
        "id": "mW5nNWerxosq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9XjFM_SIsZ2c",
        "outputId": "a6577d86-5e1e-4213-9969-1ddc970a0d16"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, MSE: 0.77319\n",
            "Epoch 100, MSE: 0.00494\n",
            "Epoch 200, MSE: 0.00315\n",
            "Epoch 300, MSE: 0.00277\n",
            "Epoch 400, MSE: 0.00243\n",
            "Epoch 500, MSE: 0.00214\n",
            "Epoch 600, MSE: 0.00188\n",
            "Epoch 700, MSE: 0.00165\n",
            "Epoch 800, MSE: 0.00145\n",
            "Epoch 900, MSE: 0.00128\n",
            "Final Training MSE: 0.00112\n",
            "Test MSE: 0.00672\n",
            "Enter x1, x2, x3: 1 2 3\n",
            "Predicted output: 1.83334\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Training Data\n",
        "train_X = np.array([\n",
        "    [0.1, 0.2, 0.3],\n",
        "    [0.2, 0.3, 0.4],\n",
        "    [0.3, 0.4, 0.5],\n",
        "    [0.5, 0.6, 0.7],\n",
        "    [0.1, 0.3, 0.5],\n",
        "    [0.2, 0.4, 0.6],\n",
        "    [0.3, 0.5, 0.7],\n",
        "    [0.4, 0.6, 0.8],\n",
        "    [0.5, 0.7, 0.1]\n",
        "])\n",
        "train_y = np.array([0.14, 0.20, 0.26, 0.38, 0.22, 0.28, 0.34, 0.40, 0.22])\n",
        "\n",
        "# Test Data\n",
        "test_X = np.array([\n",
        "    [0.6, 0.7, 0.8],\n",
        "    [0.7, 0.8, 0.9]\n",
        "])\n",
        "test_y = np.array([0.44, 0.50])\n",
        "\n",
        "# Initialize weights and bias\n",
        "weights = np.random.rand(3)\n",
        "bias = np.random.rand()\n",
        "\n",
        "# Hyperparameters\n",
        "learning_rate = 0.01\n",
        "epochs = 1000\n",
        "\n",
        "# Training the model using gradient descent\n",
        "for epoch in range(epochs):\n",
        "    predictions = np.dot(train_X, weights) + bias\n",
        "    errors = predictions - train_y\n",
        "\n",
        "    # Compute gradients\n",
        "    weight_gradients = (2 / len(train_X)) * np.dot(train_X.T, errors)\n",
        "    bias_gradient = (2 / len(train_X)) * np.sum(errors)\n",
        "\n",
        "    # Update weights and bias\n",
        "    weights -= learning_rate * weight_gradients\n",
        "    bias -= learning_rate * bias_gradient\n",
        "\n",
        "    # Calculate Mean Squared Error (MSE)\n",
        "    mse = np.mean(errors ** 2)\n",
        "    if epoch % 100 == 0:\n",
        "        print(f\"Epoch {epoch}, MSE: {mse:.5f}\")\n",
        "\n",
        "# Compute MSE on test data\n",
        "test_predictions = np.dot(test_X, weights) + bias\n",
        "test_mse = np.mean((test_predictions - test_y) ** 2)\n",
        "print(f\"Final Training MSE: {mse:.5f}\")\n",
        "print(f\"Test MSE: {test_mse:.5f}\")\n",
        "\n",
        "# User input prediction\n",
        "x1, x2, x3 = map(float, input(\"Enter x1, x2, x3: \").split())\n",
        "user_input = np.array([x1, x2, x3])\n",
        "user_prediction = np.dot(user_input, weights) + bias\n",
        "print(f\"Predicted output: {user_prediction:.5f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question_02**\n"
      ],
      "metadata": {
        "id": "MnrMIrGYxwIB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def sigmoid_derivative(x):\n",
        "    return x * (1 - x)\n",
        "\n",
        "train_X = np.array([\n",
        "    [0.1, 0.2, 0.3],\n",
        "    [0.2, 0.3, 0.4],\n",
        "    [0.3, 0.4, 0.5],\n",
        "    [0.5, 0.6, 0.7],\n",
        "    [0.1, 0.3, 0.5],\n",
        "    [0.2, 0.4, 0.6],\n",
        "    [0.3, 0.5, 0.7],\n",
        "    [0.4, 0.6, 0.8],\n",
        "    [0.5, 0.7, 0.1]\n",
        "])\n",
        "train_y = np.array([0.5349, 0.5498, 0.5646, 0.5939, 0.5548, 0.5695, 0.5842, 0.5987, 0.5548])\n",
        "\n",
        "test_X = np.array([\n",
        "    [0.6, 0.7, 0.8],\n",
        "    [0.7, 0.8, 0.9]\n",
        "])\n",
        "test_y = np.array([0.6083, 0.6225])\n",
        "\n",
        "weights = np.random.rand(3)\n",
        "bias = np.random.rand()\n",
        "\n",
        "learning_rate = 0.01\n",
        "epochs = 1000\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    linear_output = np.dot(train_X, weights) + bias\n",
        "    predictions = sigmoid(linear_output)\n",
        "    errors = predictions - train_y\n",
        "\n",
        "    d_predictions = errors * sigmoid_derivative(predictions)\n",
        "    weight_gradients = (2 / len(train_X)) * np.dot(train_X.T, d_predictions)\n",
        "    bias_gradient = (2 / len(train_X)) * np.sum(d_predictions)\n",
        "\n",
        "    weights -= learning_rate * weight_gradients\n",
        "    bias -= learning_rate * bias_gradient\n",
        "\n",
        "    mse = np.mean(errors ** 2)\n",
        "    if epoch % 100 == 0:\n",
        "        print(f\"Epoch {epoch}, MSE: {mse:.5f}\")\n",
        "\n",
        "test_predictions = sigmoid(np.dot(test_X, weights) + bias)\n",
        "test_mse = np.mean((test_predictions - test_y) ** 2)\n",
        "print(f\"Final Training MSE: {mse:.5f}\")\n",
        "print(f\"Test MSE: {test_mse:.5f}\")\n",
        "\n",
        "x1, x2, x3 = map(float, input(\"Enter x1, x2, x3: \").split())\n",
        "user_input = np.array([x1, x2, x3])\n",
        "user_prediction = sigmoid(np.dot(user_input, weights) + bias)\n",
        "print(f\"Predicted output: {user_prediction:.5f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aGLCTc8BxaWQ",
        "outputId": "2b71891b-4fc5-4fd1-fb5e-b0ba794fd605"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, MSE: 0.03783\n",
            "Epoch 100, MSE: 0.03075\n",
            "Epoch 200, MSE: 0.02445\n",
            "Epoch 300, MSE: 0.01904\n",
            "Epoch 400, MSE: 0.01455\n",
            "Epoch 500, MSE: 0.01094\n",
            "Epoch 600, MSE: 0.00811\n",
            "Epoch 700, MSE: 0.00595\n",
            "Epoch 800, MSE: 0.00432\n",
            "Epoch 900, MSE: 0.00313\n",
            "Final Training MSE: 0.00226\n",
            "Test MSE: 0.00319\n",
            "Enter x1, x2, x3: 1 2 3\n",
            "Predicted output: 0.88052\n"
          ]
        }
      ]
    }
  ]
}